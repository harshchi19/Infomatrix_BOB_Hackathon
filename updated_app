import streamlit as st
import requests
import json
import base64
import os
from azure.cognitiveservices.vision.computervision import ComputerVisionClient
from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes
from msrest.authentication import CognitiveServicesCredentials
from azure.ai.textanalytics import TextAnalyticsClient
from azure.core.credentials import AzureKeyCredential
import azure.cognitiveservices.speech as speechsdk
import io
import tempfile
import time
import PyPDF2
from pydub import AudioSegment
import pyperclip
import os

def text_to_speech(text):
    speech_config = speechsdk.SpeechConfig(subscription=SPEECH_KEY, region=SPEECH_REGION)
    speech_config.speech_synthesis_voice_name = "en-US-JennyNeural"
    
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
        temp_filename = tmp_file.name

    audio_config = speechsdk.audio.AudioOutputConfig(filename=temp_filename)
    synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)
    
    result = synthesizer.speak_text_async(text).get()
    
    if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
        with open(temp_filename, "rb") as audio_file:
            audio_data = audio_file.read()
        st.audio(audio_data, format="audio/wav")
        st.success("Text converted to speech successfully!")
    else:
        st.error(f"Speech synthesis failed: {result.reason}")
    
    
    max_attempts = 5
    for attempt in range(max_attempts):
        try:
            os.unlink(temp_filename)
            break
        except PermissionError:
            if attempt < max_attempts - 1:
                time.sleep(1)  
            else:
                st.warning("Could not delete temporary audio file. It will be removed later.")


def speech_to_text():
    speech_config = speechsdk.SpeechConfig(subscription=SPEECH_KEY, region=SPEECH_REGION)
    audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)
    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)

    st.write("Speak now...")
    result = speech_recognizer.recognize_once_async().get()

    if result.reason == speechsdk.ResultReason.RecognizedSpeech:
        return result.text
    elif result.reason == speechsdk.ResultReason.NoMatch:
        st.error("No speech could be recognized")
    elif result.reason == speechsdk.ResultReason.Canceled:
        cancellation_details = result.cancellation_details
        st.error(f"Speech Recognition canceled: {cancellation_details.reason}")
        if cancellation_details.reason == speechsdk.CancellationReason.Error:
            st.error(f"Error details: {cancellation_details.error_details}")
    
    return ""


KEY = "8019113bcf564d2c8236f3a8ef8865f0"
OPENAI_ENDPOINT = "https://prnvpwr2612bobtrial2502024.openai.azure.com/"
COGNITIVE_ENDPOINT = "https://prnvpwr2612bobtrial2502024.cognitiveservices.azure.com/"
TRANSLATOR_ENDPOINT = "https://api.cognitive.microsofttranslator.com/"
STT_ENDPOINT = "https://eastus.stt.speech.microsoft.com"
TTS_ENDPOINT = "https://eastus.tts.speech.microsoft.com"
SPEECH_KEY = "8019113bcf564d2c8236f3a8ef8865f0"  
SPEECH_REGION = "eastus"
st.set_page_config(page_title="Azure AI Demo", layout="wide")

st.markdown(
    """
    <style>
    .reportview-container {
        background: linear-gradient(to right, #4e54c8, #8f94fb);
    }
    </style>
    """,
    unsafe_allow_html=True
)


st.sidebar.title("Azure AI Services")
service = st.sidebar.selectbox(
    "Choose a service",
    ("Language", "Vision", "Speech", "OpenAI")
)


st.title("Azure AI Services Demo")

if service == "Language":
    st.header("Language Services")
    
    
    text_input = st.text_area("Enter text for analysis:")
    if st.button("Analyze"):
        try:
            text_analytics_client = TextAnalyticsClient(endpoint=COGNITIVE_ENDPOINT, credential=AzureKeyCredential(KEY))
            result = text_analytics_client.analyze_sentiment(documents=[text_input])[0]
            st.write(f"Sentiment: {result.sentiment}")
            st.write(f"Confidence scores: Positive={result.confidence_scores.positive:.2f}, Neutral={result.confidence_scores.neutral:.2f}, Negative={result.confidence_scores.negative:.2f}")
        except Exception as e:
            st.error(f"An error occurred: {str(e)}")

elif service == "Vision":
    st.header("Computer Vision")
    
    image_url = st.text_input("Enter direct image URL (should end with .jpg, .png, etc.):")
    if st.button("Analyze Image"):
        if image_url and (image_url.endswith('.jpg') or image_url.endswith('.png') or image_url.endswith('.jpeg')):
            try:
                cv_client = ComputerVisionClient(COGNITIVE_ENDPOINT, CognitiveServicesCredentials(KEY))
                features = [VisualFeatureTypes.description, VisualFeatureTypes.tags]
                results = cv_client.analyze_image(image_url, visual_features=features)
                st.image(image_url, caption="Analyzed Image", use_column_width=True)
                st.write("Description:", results.description.captions[0].text)
                st.write("Tags:", ", ".join([tag.name for tag in results.tags]))
            except Exception as e:
                st.error(f"An error occurred: {str(e)}")
        else:
            st.error("Please enter a valid direct image URL (ending with .jpg, .png, or .jpeg)")
elif service == "Speech":
    st.header("Speech Services")
    
    text_to_speak = st.text_input("Enter text to convert to speech:")
    if st.button("Convert to Speech"):
        temp_filename = None
        try:
            speech_config = speechsdk.SpeechConfig(subscription=KEY, region="eastus")
            speech_config.speech_synthesis_voice_name = "en-US-JennyNeural"
            
            
            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
                temp_filename = tmp_file.name

            audio_config = speechsdk.audio.AudioOutputConfig(filename=temp_filename)
            synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)
            
            result = synthesizer.speak_text_async(text_to_speak).get()
            
            if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
                
                with open(temp_filename, "rb") as audio_file:
                    audio_data = audio_file.read()
                st.audio(audio_data, format="audio/wav")
                st.success("Speech synthesized successfully!")
            elif result.reason == speechsdk.ResultReason.Canceled:
                cancellation_details = result.cancellation_details
                st.error(f"Speech synthesis canceled: {cancellation_details.reason}")
                if cancellation_details.reason == speechsdk.CancellationReason.Error:
                    st.error(f"Error details: {cancellation_details.error_details}")
            else:
                st.error(f"Speech synthesis failed: {result.reason}")
        except Exception as e:
            st.error(f"An error occurred: {str(e)}")
        finally:
            
            if temp_filename and os.path.exists(temp_filename):
                for _ in range(5):  
                    try:
                        os.remove(temp_filename)
                        break
                    except PermissionError:
                        time.sleep(1)  
                else:
                    st.warning("Could not delete temporary file. It will be removed automatically later.")

elif service == "OpenAI":
    st.header("OpenAI Services")
    
    
    OPENAI_KEY = "37db37e7aff6444fa6f59fcb1fc48028"
    OPENAI_ENDPOINT = "https://bobtrialinfomatrix.openai.azure.com/"

    
    if 'generated_text' not in st.session_state:
        st.session_state.generated_text = ""
    if 'prompt' not in st.session_state:
        st.session_state.prompt = ""

    st.info("""
    The default deployment name is set to "BobTrialInfomatrix". If you need to use a different deployment,
    you can change it in the input field below.
    """)

    DEPLOYMENT_NAME = st.text_input("Enter your Azure OpenAI deployment name:", value="BobTrialInfomatrix")
    
    input_option = st.radio("Choose input type:", ["Text", "PDF", "Speech to Text"])
    
    if input_option == "Text":
        st.session_state.prompt = st.text_area("Enter a prompt for text generation:", height=150)
        
        if st.button("Convert Input to Speech"):
            text_to_speech(st.session_state.prompt)
    
    elif input_option == "PDF":
        uploaded_file = st.file_uploader("Choose a PDF file", type="pdf")
        if uploaded_file is not None:
            reader = PyPDF2.PdfReader(uploaded_file)
            pdf_text = ""
            for page in reader.pages:
                pdf_text += page.extract_text() + "\n"
            
            st.success("PDF uploaded successfully!")
            
            user_question = st.text_input("Ask a question about the PDF:")
            
            if user_question:
                st.session_state.prompt = f"""The following is the content of a PDF document:

{pdf_text}

Based on the above content, please answer the following question:
{user_question}

Answer:"""

                if st.button("Convert Question to Speech"):
                    text_to_speech(user_question)
    
    elif input_option == "Speech to Text":
        if st.button("Start Speech Recognition"):
            with st.spinner("Listening..."):
                recognized_text = speech_to_text()
                if recognized_text:
                    st.session_state.prompt = recognized_text
                    st.text_area("Transcribed text:", value=st.session_state.prompt, height=150)
                else:
                    st.error("No speech could be recognized")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        max_tokens = st.slider("Max Tokens", min_value=50, max_value=2000, value=500, step=50)
    with col2:
        temperature = st.slider("Temperature", min_value=0.0, max_value=1.0, value=0.7, step=0.1)
    with col3:
        top_p = st.slider("Top P", min_value=0.0, max_value=1.0, value=1.0, step=0.1)

    def generate_text(prompt):
        headers = {
            "Content-Type": "application/json",
            "api-key": OPENAI_KEY
        }
        data = {
            "prompt": prompt,
            "max_tokens": max_tokens,
            "temperature": temperature,
            "top_p": top_p,
            "frequency_penalty": 0,
            "presence_penalty": 0,
            "best_of": 1,
            "stop": None
        }
        try:
            with st.spinner("Generating text..."):
                response = requests.post(f"{OPENAI_ENDPOINT}/openai/deployments/{DEPLOYMENT_NAME}/completions?api-version=2023-05-15", headers=headers, json=data)
                response.raise_for_status()
                result = response.json()
                return result['choices'][0]['text']
        except requests.exceptions.RequestException as e:
            st.error(f"Error: {e}")
            if response.status_code == 404:
                st.error("Deployment not found. Please check your deployment name and try again.")
            else:
                st.error(f"Detailed error: {response.text}")
            return None

    if st.button("Generate") and DEPLOYMENT_NAME and st.session_state.prompt.strip():
        st.session_state.generated_text = generate_text(st.session_state.prompt)
        if st.session_state.generated_text:
            st.subheader("Generated Text:")
            st.write(st.session_state.generated_text)
            
            st.text_area("Copy generated text:", value=st.session_state.generated_text, height=300)
            if st.button("Copy to Clipboard"):
                pyperclip.copy(st.session_state.generated_text)
                st.success("Text copied to clipboard!")

    
    if st.session_state.generated_text:
        if st.button("Convert Output to Speech"):
            text_to_speech(st.session_state.generated_text)

st.sidebar.markdown("---")
